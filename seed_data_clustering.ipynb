{"cells":[{"cell_type":"code","source":["# here idea is to use pyspark for clustering the data of seed_dataset\n\n# first we have used jupyter notebook at local machine to import data from github then added column names and then\n#remove class from the dataset. after saved the dataset as csv file. that file is now uploaded to the datbricks and clustering is prerformed using pyspark. \nfrom pyspark.sql import SparkSession"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# loading dataset as dataframe\ndf = spark.read.csv('/FileStore/tables/seeds_dataset.csv', inferSchema=True, header=True)\ndf.show(3) # in spark we use show or take and argument will be number of element to be passed."],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+---------+-----------+-----------------+------------------+---------------------+----------------+\n area|perimeter|compactness| length_of_kernel|   width_of_kernel|asymmetry_coefficient|length_of_groove|\n+-----+---------+-----------+-----------------+------------------+---------------------+----------------+\n15.26|    14.84|      0.871|            5.763|             3.312|                2.221|            5.22|\n14.88|    14.57|     0.8811|5.553999999999999|             3.333|                1.018|           4.956|\n14.29|    14.09|      0.905|            5.291|3.3369999999999997|                2.699|           4.825|\n+-----+---------+-----------+-----------------+------------------+---------------------+----------------+\nonly showing top 3 rows\n\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["df.printSchema() # printing schema of the dataset"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- area: double (nullable = true)\n-- perimeter: double (nullable = true)\n-- compactness: double (nullable = true)\n-- length_of_kernel: double (nullable = true)\n-- width_of_kernel: double (nullable = true)\n-- asymmetry_coefficient: double (nullable = true)\n-- length_of_groove: double (nullable = true)\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler # in spark api we have to convert data to vectors in order to run the model.\n# kmeans is imported from pyspark.ml.clustering\nfrom pyspark.ml.clustering import KMeans\n\n# creating an instance of the vector assembler \nassembler = VectorAssembler(inputCols = df.columns, outputCol = 'features')\n\n# transforming dataframe into vector assembler \nfinal_df = assembler.transform(df)\nfinal_df.show(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+---------+-----------+-----------------+------------------+---------------------+----------------+--------------------+\n area|perimeter|compactness| length_of_kernel|   width_of_kernel|asymmetry_coefficient|length_of_groove|            features|\n+-----+---------+-----------+-----------------+------------------+---------------------+----------------+--------------------+\n15.26|    14.84|      0.871|            5.763|             3.312|                2.221|            5.22|[15.26,14.84,0.87...|\n14.88|    14.57|     0.8811|5.553999999999999|             3.333|                1.018|           4.956|[14.88,14.57,0.88...|\n14.29|    14.09|      0.905|            5.291|3.3369999999999997|                2.699|           4.825|[14.29,14.09,0.90...|\n+-----+---------+-----------+-----------------+------------------+---------------------+----------------+--------------------+\nonly showing top 3 rows\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["final_df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- area: double (nullable = true)\n-- perimeter: double (nullable = true)\n-- compactness: double (nullable = true)\n-- length_of_kernel: double (nullable = true)\n-- width_of_kernel: double (nullable = true)\n-- asymmetry_coefficient: double (nullable = true)\n-- length_of_groove: double (nullable = true)\n-- features: vector (nullable = true)\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# in clustering we have to scale the features so as to reduce the distance and which helps in computation become faster\nfrom pyspark.ml.feature import StandardScaler\n\n# created instance of the standard scaler\nscaler = StandardScaler(inputCol = 'features', outputCol = 'scaledFeatures')\n\n#fitting the vector data and transforming with scaler transformation\nscaler_model = scaler.fit(final_df)\nfinal_df = scaler_model.transform(final_df)\nfinal_df.show(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+---------+-----------+-----------------+------------------+---------------------+----------------+--------------------+--------------------+\n area|perimeter|compactness| length_of_kernel|   width_of_kernel|asymmetry_coefficient|length_of_groove|            features|      scaledFeatures|\n+-----+---------+-----------+-----------------+------------------+---------------------+----------------+--------------------+--------------------+\n15.26|    14.84|      0.871|            5.763|             3.312|                2.221|            5.22|[15.26,14.84,0.87...|[5.24452795332028...|\n14.88|    14.57|     0.8811|5.553999999999999|             3.333|                1.018|           4.956|[14.88,14.57,0.88...|[5.11393027165175...|\n14.29|    14.09|      0.905|            5.291|3.3369999999999997|                2.699|           4.825|[14.29,14.09,0.90...|[4.91116018695588...|\n+-----+---------+-----------+-----------------+------------------+---------------------+----------------+--------------------+--------------------+\nonly showing top 3 rows\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# first row of the final scaled vecorized dataset\nfinal_df.take(1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>[Row(area=15.26, perimeter=14.84, compactness=0.871, length_of_kernel=5.763, width_of_kernel=3.312, asymmetry_coefficient=2.221, length_of_groove=5.22, features=DenseVector([15.26, 14.84, 0.871, 5.763, 3.312, 2.221, 5.22]), scaledFeatures=DenseVector([5.2445, 11.3633, 36.8608, 13.0072, 8.7685, 1.4772, 10.621]))]\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["\n#instantiated kmeans with 3 cluster \nkmeans = KMeans(featuresCol = 'scaledFeatures', k=3)\n\n# fitting the model\nmodel = kmeans.fit(final_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["# sum of square error within cluster\n\n#sum of squared  error within cluster is used to get the right number of clusters for the model. we use elbow method in which we plot WSSSE on y axis and # number of cluster on x axis . as we move to more number of cluster error reduced but where we see that curve is started changing gradually that point we # take as optimum number of cluster. for more info check Elbow method.\nprint('WSSSE:', model.computeCost(final_df))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&apos;WSSSE:&apos;, 429.07558670547337)\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["# cluster centeroids\ncenters = model.clusterCenters()\nprint(centers)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[array([  6.31670546,  12.37109759,  37.39491396,  13.91155062,\n         9.748067  ,   2.39850262,  12.2661748 ]), array([  4.87257659,  10.88120146,  37.27692543,  12.3410157 ,\n         8.55443412,   1.81649411,  10.32998598]), array([  4.06105916,  10.13979506,  35.80536984,  11.82133095,\n         7.50395937,   3.27185132,  10.42126018])]\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["# prdicting the data. transform method is same as sklearn model.predict. it gives many output but we are printing scaledfeatures and prediction\nmodel.transform(final_df).select('scaledFeatures', 'prediction').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+----------+\n      scaledFeatures|prediction|\n+--------------------+----------+\n[5.24452795332028...|         1|\n[5.11393027165175...|         1|\n[4.91116018695588...|         1|\n[4.75650503761158...|         1|\n[5.54696468981581...|         1|\n[4.94209121682475...|         1|\n[5.04863143081749...|         1|\n[4.84929812721816...|         1|\n[5.71536696354628...|         0|\n[5.65006812271202...|         0|\n[5.24452795332028...|         1|\n[4.82180387844584...|         1|\n[4.77368894309428...|         1|\n[4.73588435103234...|         1|\n[4.72213722664617...|         1|\n[5.01426361985209...|         1|\n[4.80805675405968...|         1|\n[5.39230954047151...|         1|\n[5.05206821191403...|         1|\n[4.37158555479908...|         2|\n+--------------------+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["model.transform(final_df).show() # all from transfrom method"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+---------+-----------+------------------+------------------+---------------------+------------------+--------------------+--------------------+----------+\n area|perimeter|compactness|  length_of_kernel|   width_of_kernel|asymmetry_coefficient|  length_of_groove|            features|      scaledFeatures|prediction|\n+-----+---------+-----------+------------------+------------------+---------------------+------------------+--------------------+--------------------+----------+\n15.26|    14.84|      0.871|             5.763|             3.312|                2.221|              5.22|[15.26,14.84,0.87...|[5.24452795332028...|         1|\n14.88|    14.57|     0.8811| 5.553999999999999|             3.333|                1.018|             4.956|[14.88,14.57,0.88...|[5.11393027165175...|         1|\n14.29|    14.09|      0.905|             5.291|3.3369999999999997|                2.699|             4.825|[14.29,14.09,0.90...|[4.91116018695588...|         1|\n13.84|    13.94|     0.8955|             5.324|3.3789999999999996|                2.259|             4.805|[13.84,13.94,0.89...|[4.75650503761158...|         1|\n16.14|    14.99|     0.9034|5.6579999999999995|             3.562|                1.355|             5.175|[16.14,14.99,0.90...|[5.54696468981581...|         1|\n14.38|    14.21|     0.8951|             5.386|             3.312|   2.4619999999999997|             4.956|[14.38,14.21,0.89...|[4.94209121682475...|         1|\n14.69|    14.49|     0.8799|             5.563|             3.259|   3.5860000000000003| 5.218999999999999|[14.69,14.49,0.87...|[5.04863143081749...|         1|\n14.11|     14.1|     0.8911|              5.42|             3.302|                  2.7|               5.0|[14.11,14.1,0.891...|[4.84929812721816...|         1|\n16.63|    15.46|     0.8747|             6.053|             3.465|                 2.04| 5.877000000000001|[16.63,15.46,0.87...|[5.71536696354628...|         0|\n16.44|    15.25|      0.888|5.8839999999999995|             3.505|                1.969|5.5329999999999995|[16.44,15.25,0.88...|[5.65006812271202...|         0|\n15.26|    14.85|     0.8696|5.7139999999999995|             3.242|                4.543|             5.314|[15.26,14.85,0.86...|[5.24452795332028...|         1|\n14.03|    14.16|     0.8796|             5.438|             3.201|   1.7169999999999999|             5.001|[14.03,14.16,0.87...|[4.82180387844584...|         1|\n13.89|    14.02|      0.888|             5.439|             3.199|                3.986|             4.738|[13.89,14.02,0.88...|[4.77368894309428...|         1|\n13.78|    14.06|     0.8759|             5.479|             3.156|                3.136|             4.872|[13.78,14.06,0.87...|[4.73588435103234...|         1|\n13.74|    14.05|     0.8744|             5.482|             3.114|                2.932|             4.825|[13.74,14.05,0.87...|[4.72213722664617...|         1|\n14.59|    14.28|     0.8993|             5.351|             3.333|                4.185| 4.781000000000001|[14.59,14.28,0.89...|[5.01426361985209...|         1|\n13.99|    13.83|     0.9183|             5.119|             3.383|                5.234| 4.781000000000001|[13.99,13.83,0.91...|[4.80805675405968...|         1|\n15.69|    14.75|     0.9058|             5.527|             3.514|                1.599|             5.046|[15.69,14.75,0.90...|[5.39230954047151...|         1|\n 14.7|    14.21|     0.9153|             5.205|             3.466|                1.767|             4.649|[14.7,14.21,0.915...|[5.05206821191403...|         1|\n12.72|    13.57|     0.8686|             5.226|             3.049|                4.102|             4.914|[12.72,13.57,0.86...|[4.37158555479908...|         2|\n+-----+---------+-----------+------------------+------------------+---------------------+------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13}],"metadata":{"name":"seed_data_clustering","notebookId":3917155236030175},"nbformat":4,"nbformat_minor":0}
